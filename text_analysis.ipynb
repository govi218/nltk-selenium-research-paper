{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_list = []\n",
    "with open('contrib_blob', 'r') as contrib:\n",
    "    for line in contrib:\n",
    "        pos_list.append(nltk.pos_tag(nltk.word_tokenize(line)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pos_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def end_str_fn(pos_lists):\n",
    "    \"\"\" Get the verb predicates for a list of paragraphs (each being a list of string, POS tuples. \"\"\"\n",
    "    end_strs = []\n",
    "    # iterate through paragraphs\n",
    "    for l in pos_lists:\n",
    "        cur_pos = ''\n",
    "        i = 0\n",
    "        while i < len(l):\n",
    "            cur_pos = l[i][1]\n",
    "            # find vp\n",
    "            if cur_pos in ['VBD','VBN']:\n",
    "                # loop till end of sentence\n",
    "                end_str = ''\n",
    "                while cur_pos != '.':\n",
    "                    end_str += l[i][0] + ' '\n",
    "                    i += 1\n",
    "                    cur_pos = l[i][1]\n",
    "                end_strs.append(end_str)\n",
    "                i += 1\n",
    "            i += 1\n",
    "    return end_strs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "\n",
    "pos_list_locs = []\n",
    "i = 0\n",
    "# needs to be made dynamic based on # of CPU cores\n",
    "while i < len(pos_list):\n",
    "    pos_list_loc = []\n",
    "    while i%3 != 2:\n",
    "        pos_list_loc.append(pos_list[i])\n",
    "        i += 1\n",
    "    pos_list_locs.append(pos_list_loc)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = mp.Pool()\n",
    "\n",
    "res = pool.map(end_str_fn, pos_list_locs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "icmje_criterae = [\"Substantial contributions to the conception or design of the work; or the acquisition, analysis,\"+\n",
    "                      \" or interpretation of data for the work\",\"Drafting the work or revising it critically for \"+\n",
    "                      \"important intellectual content\",\"Final approval of the version to be published\",\"Agreement to\"+\n",
    "                      \" be accountable for all aspects of the work in ensuring that questions related to the accuracy or\" +\n",
    "                      \" integrity of any part of the work are appropriately investigated and resolved.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lst = []\n",
    "# for l in pos_list:\n",
    "#      lst += l\n",
    "\n",
    "# lst2 = [x for x in lst if x[1] in ['VBD', 'VBN']]\n",
    "# d = {}\n",
    "# for x in lst2:\n",
    "#     if x not in d:\n",
    "#         d[x] = 1\n",
    "#     else:\n",
    "#         d[x] += 1\n",
    "\n",
    "# d\n",
    "\n",
    "# verbs = filter(lambda x:x[1]=='NN' ,pos_list)\n",
    "\n",
    "# verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
